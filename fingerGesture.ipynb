{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hand\n",
    "import cv2  # OpenCV 라이브러리 import\n",
    "import sys  # sys 모듈 import\n",
    "import mediapipe as mp  # MediaPipe 패키지 import하고 mp라는 별칭으로 사용하겠다는 뜻.\n",
    "\n",
    "# MediaPipe 패키지에서 사용할 기능들.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands  # 손 인식을 위한 객체\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # 비디오 캡처 객체 생성\n",
    "\n",
    "if not cap.isOpened():  # 연결 확인\n",
    "    print(\"Camera is not opened\")\n",
    "    sys.exit(1)  # 프로그램 종료\n",
    "\n",
    "hands = mp_hands.Hands()  # 손 인식 객체 생성\n",
    "\n",
    "while True:  # 무한 반복\n",
    "    res, frame = cap.read()  # 카메라 데이터 읽기\n",
    "\n",
    "    if not res:  # 프레임 읽었는지 확인\n",
    "        print(\"Camera error\")\n",
    "        break  # 반복문 종료\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # 셀프 카메라처럼 좌우 반전\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # 미디어파이프에서 인식 가능한 색공간으로 변경\n",
    "    results = hands.process(image)  # 이미지에서 손을 찾고 결과를 반환\n",
    "\n",
    "    if results.multi_hand_landmarks:  # 손이 인식되었는지 확인\n",
    "        for hand_landmarks in results.multi_hand_landmarks:  # 반복문을 활용해 인식된 손의 주요 부분을 그림으로 그려 표현\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style(),\n",
    "            )\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Hands\", frame)  # 영상을 화면에 출력.\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF  # 키보드 입력받기\n",
    "    if key == 27:  # ESC를 눌렀을 경우\n",
    "        break  # 반복문 종료\n",
    "\n",
    "cv2.destroyAllWindows()  # 영상 창 닫기\n",
    "cap.release()  # 비디오 캡처 객체 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fingertip\n",
    "#https://www.youtube.com/watch?v=OrzYIv87hmk&list=PLy_0osTUNJ5SqYHqM1dqV5R7WJUIU6TwN&index=20&t=377s\n",
    "\n",
    "import cv2  # OpenCV 라이브러리 import\n",
    "import sys  # sys 모듈 import\n",
    "import mediapipe as mp  # MediaPipe 패키지 import하고 mp라는 별칭으로 사용하겠다는 뜻.\n",
    "import math  # math 모듈 import\n",
    "\n",
    "# 거리 계산 함수 선언\n",
    "def distance(p1, p2):\n",
    "    return math.dist((p1.x, p1.y), (p2.x, p2.y))  # 두 점 p1, p2의 x, y 좌표로 거리를 계산한다.\n",
    "\n",
    "\n",
    "# MediaPipe 패키지에서 사용할 기능들.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands  # 손 인식을 위한 객체\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # 비디오 캡처 객체 생성\n",
    "\n",
    "if not cap.isOpened():  # 연결 확인\n",
    "    print(\"Camera is not opened\")\n",
    "    sys.exit(1)  # 프로그램 종료\n",
    "\n",
    "hands = mp_hands.Hands()  # 손 인식 객체 생성\n",
    "\n",
    "while True:  # 무한 반복\n",
    "    res, frame = cap.read()  # 카메라 데이터 읽기\n",
    "\n",
    "    if not res:  # 프레임 읽었는지 확인\n",
    "        print(\"Camera error\")\n",
    "        break  # 반복문 종료\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # 셀프 카메라처럼 좌우 반전\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # 미디어파이프에서 인식 가능한 색공간으로 변경\n",
    "    results = hands.process(image)  # 이미지에서 손을 찾고 결과를 반환\n",
    "\n",
    "    if results.multi_hand_landmarks:  # 손이 인식되었는지 확인\n",
    "        for hand_landmarks in results.multi_hand_landmarks:  # 반복문을 활용해 인식된 손의 주요 부분을 그림으로 그려 표현\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style(),\n",
    "            )\n",
    "\n",
    "            points = hand_landmarks.landmark  #  landmark 좌표 정보들을 points라는 변수로 활용\n",
    "\n",
    "            # 엄지손가락부터 새끼손가락까지 손가락이 펴졌는지 확인하고 이미지에 출력한다.\n",
    "            # 엄지손가락 확인하기\n",
    "            if distance(points[4], points[9]) < distance(points[3], points[9]):\n",
    "                fingers = \"0\"  # 접혔으면 0\n",
    "            else:\n",
    "                fingers = \"1\"  # 펴졌으면 1\n",
    "            cv2.putText(  # 0 또는 1을 이미지에 출력한다.\n",
    "                frame,\n",
    "                fingers,\n",
    "                (int(points[4].x * frame.shape[1]), int(points[4].y * frame.shape[0])),\n",
    "                cv2.FONT_HERSHEY_COMPLEX,\n",
    "                1,\n",
    "                (0, 255, 0),\n",
    "                5,\n",
    "            )\n",
    "\n",
    "            # 나머지 손가락 확인하기\n",
    "            for i in range(8, 21, 4):\n",
    "                if distance(points[i], points[0]) < distance(points[i - 1], points[0]):\n",
    "                    fingers = \"0\"  # 접혔으면 0\n",
    "                else:\n",
    "                    fingers = \"1\"  # 펴졌으면 1\n",
    "                cv2.putText(  # 0 또는 1을 이미지에 출력한다.\n",
    "                    frame,\n",
    "                    fingers,\n",
    "                    (int(points[i].x * frame.shape[1]), int(points[i].y * frame.shape[0])),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX,\n",
    "                    1,\n",
    "                    (0, 255, 0),\n",
    "                    5,\n",
    "                )\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Hands\", frame)  # 영상을 화면에 출력.\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF  # 키보드 입력받기\n",
    "    if key == 27:  # ESC를 눌렀을 경우\n",
    "        break  # 반복문 종료\n",
    "\n",
    "cv2.destroyAllWindows()  # 영상 창 닫기\n",
    "cap.release()  # 비디오 캡처 객체 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hand player\n",
    "import cv2  # OpenCV 라이브러리 import\n",
    "import sys  # sys 모듈 import\n",
    "import mediapipe as mp  # MediaPipe 패키지 import하고 mp라는 별칭으로 사용하겠다는 뜻.\n",
    "import math  # math 모듈 import\n",
    "import numpy as np  # numpy 패키지를 import하고 np라는 별칭으로 사용\n",
    "\n",
    "# 거리 계산 함수 선언\n",
    "def distance(p1, p2):\n",
    "    return math.dist((p1.x, p1.y), (p2.x, p2.y))  # 두 점 p1, p2의 x, y 좌표로 거리를 계산한다.\n",
    "\n",
    "\n",
    "# MediaPipe 패키지에서 사용할 기능들.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands  # 손 인식을 위한 객체\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # 비디오 캡처 객체 생성\n",
    "video = cv2.VideoCapture(\"Boat.mp4\")  # 동영상 재생을 위한 비디오 캡처 객체 생성\n",
    "\n",
    "if not cap.isOpened():  # 연결 확인\n",
    "    print(\"Camera is not opened\")\n",
    "    sys.exit(1)  # 프로그램 종료\n",
    "\n",
    "if not video.isOpened():  # 동영상 파일 확인\n",
    "    print(\"Video is not opened\")\n",
    "    sys.exit(1)  # 프로그램 종료\n",
    "\n",
    "hands = mp_hands.Hands(max_num_hands=1)  # 손 인식 객체 생성, max_num_hands를 1로 설정하여 1개의 손만 인식한다.\n",
    "\n",
    "end = video.get(cv2.CAP_PROP_FRAME_COUNT)  # 동영상 파일의 전체 frame 수를 가져옵니다.\n",
    "w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # 카메라로 촬영하는 영상의 가로 길이를 가져옵니다.\n",
    "\n",
    "video_res, video_frame = video.read()  # 동영상 데이터 읽기\n",
    "while True:  # 무한 반복\n",
    "    res, frame = cap.read()  # 카메라 데이터 읽기\n",
    "\n",
    "    if not res:  # 프레임 읽었는지 확인\n",
    "        print(\"Camera error\")\n",
    "        break  # 반복문 종료\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # 셀프 카메라처럼 좌우 반전\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # 미디어파이프에서 인식 가능한 색공간으로 변경\n",
    "    results = hands.process(image)  # 이미지에서 손을 찾고 결과를 반환\n",
    "\n",
    "    hand_shape = \"\"\n",
    "    if results.multi_hand_landmarks:  # 손이 인식되었는지 확인\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]  # 1개의 손만 인식하므로 결과를 hand_landmarks 변수에 저장\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style(),\n",
    "        )\n",
    "\n",
    "        points = hand_landmarks.landmark  #  landmark 좌표 정보들을 points라는 변수로 활용\n",
    "\n",
    "        # 엄지손가락부터 새끼손가락까지 손가락이 펴졌는지 확인한다.\n",
    "        fingers = [0, 0, 0, 0, 0]  # 편 손가락을 확인하기 위한 변수, 엄지손가락 ~ 새끼손가락 순서로 값을 확인한다.\n",
    "\n",
    "        # 엄지손가락 확인하기\n",
    "        if distance(points[4], points[9]) > distance(points[3], points[9]):\n",
    "            fingers[0] = 1  # 폈으면 fingers에 1을 할당한다.\n",
    "\n",
    "        # 나머지 손가락 확인하기\n",
    "        for i in range(1, 5):  # 검지 ~ 새끼손가락 순서로 확인한다.\n",
    "            if distance(points[4 * (i + 1)], points[0]) > distance(\n",
    "                points[4 * (i + 1) - 1], points[0]\n",
    "            ):\n",
    "                fingers[i] = 1  # 폈으면 해당하는 손가락 fingers[i]에 1을 할당한다.\n",
    "\n",
    "        # 펴진 손가락의 개수에 따라 모양을 인식하고 이미지에 출력한다.\n",
    "        if fingers == [0, 0, 0, 0, 0]:  # 손가락이 모두 접힌 경우\n",
    "            hand_shape = \"rock\"\n",
    "        elif distance(points[4], points[8]) < 0.1 and fingers[2:] == [\n",
    "            1,\n",
    "            1,\n",
    "            1,\n",
    "        ]:  # 엄지 손가락과 검지 손가락이 닿아있고, 나머지 손가락 3개가 펴진 경우\n",
    "            pos = int(\n",
    "                np.interp(points[8].x * w, (50, w - 50), (1, end - 1))\n",
    "            )  # 캠 화면의 손가락의 위치에 따라 동영상의 프레임 위치를 구한다.\n",
    "            video.set(cv2.CAP_PROP_POS_FRAMES, pos)  # 프레임을 이동한다.\n",
    "            hand_shape = \"OK\"\n",
    "\n",
    "        cv2.putText(  # 인식된 내용을 이미지에 출력한다.\n",
    "            frame,\n",
    "            hand_shape,\n",
    "            (int(points[12].x * frame.shape[1]), int(points[12].y * frame.shape[0])),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            3,\n",
    "            (0, 255, 0),\n",
    "            5,\n",
    "        )\n",
    "\n",
    "    if hand_shape != \"rock\" and video.get(cv2.CAP_PROP_POS_FRAMES) != end:  # 동영상이 끝나지 않았을 경우\n",
    "        video_res, video_frame = video.read()  # 동영상 데이터 읽기\n",
    "        if not video_res:  # 프레임 읽었는지 확인\n",
    "            print(\"Video error\")\n",
    "            break  # 반복문 종료\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Hands\", frame)  # 영상을 화면에 출력.\n",
    "    cv2.imshow(\"video\", video_frame)  # 영상을 화면에 출력.\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF  # 키보드 입력받기\n",
    "    if key == 27:  # ESC를 눌렀을 경우\n",
    "        break  # 반복문 종료\n",
    "\n",
    "cv2.destroyAllWindows()  # 영상 창 닫기\n",
    "cap.release()  # 비디오 캡처 객체 해제\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#주먹 가위 보 인식\n",
    "import cv2  # OpenCV 라이브러리 import\n",
    "import sys  # sys 모듈 import\n",
    "import mediapipe as mp  # MediaPipe 패키지 import하고 mp라는 별칭으로 사용하겠다는 뜻.\n",
    "import math  # math 모듈 import\n",
    "\n",
    "# 거리 계산 함수 선언\n",
    "def distance(p1, p2):\n",
    "    return math.dist((p1.x, p1.y), (p2.x, p2.y))  # 두 점 p1, p2의 x, y 좌표로 거리를 계산한다.\n",
    "\n",
    "\n",
    "# MediaPipe 패키지에서 사용할 기능들.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands  # 손 인식을 위한 객체\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # 비디오 캡처 객체 생성\n",
    "\n",
    "if not cap.isOpened():  # 연결 확인\n",
    "    print(\"Camera is not opened\")\n",
    "    sys.exit(1)  # 프로그램 종료\n",
    "\n",
    "hands = mp_hands.Hands()  # 손 인식 객체 생성\n",
    "\n",
    "while True:  # 무한 반복\n",
    "    res, frame = cap.read()  # 카메라 데이터 읽기\n",
    "\n",
    "    if not res:  # 프레임 읽었는지 확인\n",
    "        print(\"Camera error\")\n",
    "        break  # 반복문 종료\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # 셀프 카메라처럼 좌우 반전\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # 미디어파이프에서 인식 가능한 색공간으로 변경\n",
    "    results = hands.process(image)  # 이미지에서 손을 찾고 결과를 반환\n",
    "\n",
    "    if results.multi_hand_landmarks:  # 손이 인식되었는지 확인\n",
    "        for hand_landmarks in results.multi_hand_landmarks:  # 반복문을 활용해 인식된 손의 주요 부분을 그림으로 그려 표현\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style(),\n",
    "            )\n",
    "\n",
    "            points = hand_landmarks.landmark  #  landmark 좌표 정보들을 points라는 변수로 활용\n",
    "\n",
    "            # 엄지손가락부터 새끼손가락까지 손가락이 펴졌는지 확인한다.\n",
    "            fingers = 0  # 편 손가락의 숫자를 세기 위한 변수\n",
    "\n",
    "            # 엄지손가락 확인하기\n",
    "            if distance(points[4], points[9]) > distance(points[3], points[9]):\n",
    "                fingers += 1  # 폈으면 fingers에 1을 더한다.\n",
    "\n",
    "            # 나머지 손가락 확인하기\n",
    "            for i in range(8, 21, 4):\n",
    "                if distance(points[i], points[0]) > distance(points[i - 1], points[0]):\n",
    "                    fingers += 1  # 폈으면 fingers에 1을 더한다.\n",
    "\n",
    "            # 펴진 손가락의 개수에 따라 모양을 인식하고 이미지에 출력한다.\n",
    "            if fingers == 0:  # 손가락이 모두 접힌 경우\n",
    "                hand_shape = \"rock\"  # 바위\n",
    "            elif fingers == 2:  # 손가락이 2개 펴진 경우\n",
    "                hand_shape = \"scissors\"  # 가위\n",
    "            elif fingers == 5:  # 손가락이 5개 모두 펴진 경우\n",
    "                hand_shape = \"paper\"  # 보\n",
    "            else:  # 가위바위보 모양이 아닌 경우\n",
    "                hand_shape = \"\"  # 내용을 출력하지 않음\n",
    "            cv2.putText(  # 인식된 내용을 이미지에 출력한다.\n",
    "                frame,\n",
    "                hand_shape,\n",
    "                (int(points[12].x * frame.shape[1]), int(points[12].y * frame.shape[0])),\n",
    "                cv2.FONT_HERSHEY_COMPLEX,\n",
    "                3,\n",
    "                (0, 255, 0),\n",
    "                5,\n",
    "            )\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Hands\", frame)  # 영상을 화면에 출력.\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF  # 키보드 입력받기\n",
    "    if key == 27:  # ESC를 눌렀을 경우\n",
    "        break  # 반복문 종료\n",
    "\n",
    "cv2.destroyAllWindows()  # 영상 창 닫기\n",
    "cap.release()  # 비디오 캡처 객체 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thumb-up, OK싸인 인식\n",
    "import cv2  # OpenCV 라이브러리 import\n",
    "import sys  # sys 모듈 import\n",
    "import mediapipe as mp  # MediaPipe 패키지 import하고 mp라는 별칭으로 사용하겠다는 뜻.\n",
    "import math  # math 모듈 import\n",
    "\n",
    "# 거리 계산 함수 선언\n",
    "def distance(p1, p2):\n",
    "    return math.dist((p1.x, p1.y), (p2.x, p2.y))  # 두 점 p1, p2의 x, y 좌표로 거리를 계산한다.\n",
    "\n",
    "\n",
    "# MediaPipe 패키지에서 사용할 기능들.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands  # 손 인식을 위한 객체\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # 비디오 캡처 객체 생성\n",
    "\n",
    "if not cap.isOpened():  # 연결 확인\n",
    "    print(\"Camera is not opened\")\n",
    "    sys.exit(1)  # 프로그램 종료\n",
    "\n",
    "hands = mp_hands.Hands()  # 손 인식 객체 생성\n",
    "\n",
    "while True:  # 무한 반복\n",
    "    res, frame = cap.read()  # 카메라 데이터 읽기\n",
    "\n",
    "    if not res:  # 프레임 읽었는지 확인\n",
    "        print(\"Camera error\")\n",
    "        break  # 반복문 종료\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # 셀프 카메라처럼 좌우 반전\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # 미디어파이프에서 인식 가능한 색공간으로 변경\n",
    "    results = hands.process(image)  # 이미지에서 손을 찾고 결과를 반환\n",
    "\n",
    "    if results.multi_hand_landmarks:  # 손이 인식되었는지 확인\n",
    "        for hand_landmarks in results.multi_hand_landmarks:  # 반복문을 활용해 인식된 손의 주요 부분을 그림으로 그려 표현\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style(),\n",
    "            )\n",
    "\n",
    "            points = hand_landmarks.landmark  #  landmark 좌표 정보들을 points라는 변수로 활용\n",
    "\n",
    "            # 엄지손가락부터 새끼손가락까지 손가락이 펴졌는지 확인한다.\n",
    "            fingers = [0, 0, 0, 0, 0]  # 편 손가락을 확인하기 위한 변수, 엄지손가락 ~ 새끼손가락 순서로 값을 확인한다.\n",
    "\n",
    "            # 엄지손가락 확인하기\n",
    "            if distance(points[4], points[9]) > distance(points[3], points[9]):\n",
    "                fingers[0] = 1  # 폈으면 fingers[0]에 1을 할당한다.\n",
    "\n",
    "            # 나머지 손가락 확인하기\n",
    "            for i in range(1, 5):  # 검지손가락 ~ 새끼손가락 순서로 확인한다.\n",
    "                if distance(points[4 * (i + 1)], points[0]) > distance(\n",
    "                    points[4 * (i + 1) - 1], points[0]\n",
    "                ):\n",
    "                    fingers[i] = 1  # 폈으면 해당하는 손가락 fingers[i]에 1을 할당한다.\n",
    "\n",
    "            # 펴진 손가락의 개수에 따라 모양을 인식하고 이미지에 출력한다.\n",
    "            if fingers[0] == 1 and fingers[1:] == [0, 0, 0, 0]:  # 엄지손가락만 펴고 나머지 손가락이 모두 접힌 경우\n",
    "                hand_shape = \"thumbs up\"  # 엄지를 올렸다.\n",
    "            elif distance(points[4], points[8]) < 0.1 and fingers[2:] == [\n",
    "                1,\n",
    "                1,\n",
    "                1,\n",
    "            ]:  # 엄지 손가락과 검지 손가락이 닿아있고, 나머지 손가락 3개가 펴진 경우\n",
    "                hand_shape = \"Ok\"  # Ok\n",
    "            else:  # 두 가지 모양이 아닌 경우\n",
    "                hand_shape = \"\"  # 내용을 출력하지 않음\n",
    "            cv2.putText(  # 인식된 내용을 이미지에 출력한다.\n",
    "                frame,\n",
    "                hand_shape,\n",
    "                (int(points[12].x * frame.shape[1]), int(points[12].y * frame.shape[0])),\n",
    "                cv2.FONT_HERSHEY_COMPLEX,\n",
    "                3,\n",
    "                (0, 255, 0),\n",
    "                5,\n",
    "            )\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Hands\", frame)  # 영상을 화면에 출력.\n",
    "\n",
    "    key = cv2.waitKey(5) & 0xFF  # 키보드 입력받기\n",
    "    if key == 27:  # ESC를 눌렀을 경우\n",
    "        break  # 반복문 종료\n",
    "\n",
    "cv2.destroyAllWindows()  # 영상 창 닫기\n",
    "cap.release()  # 비디오 캡처 객체 해제"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PGPU",
   "language": "python",
   "name": "pgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
